{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/srushtidayanand/MAML_Meta-learning/blob/main/GAN_MAML_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-8362m0bCoeE"
      },
      "outputs": [],
      "source": [
        "import torch  # Core PyTorch library\n",
        "import torch.nn as nn  # Neural network modules (layers, loss functions)\n",
        "import torch.optim as optim  # Optimizers like SGD, Adam\n",
        "import torchvision.transforms as transforms  # Image preprocessing tools\n",
        "from torchvision.datasets import MNIST  # MNIST dataset (handwritten digits)\n",
        "from torch.utils.data import DataLoader, Subset  # For batching and dataset splitting\n",
        "import numpy as npa  # NumPy for array operations (alias `npa`)\n",
        "import matplotlib.pyplot as plt  # Plotting library\n",
        "from tqdm import tqdm  # Progress bar for loops\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CjbtcuaJ_Gqy"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aXzUJbvcCsuc",
        "outputId": "15d14e71-6a74-481f-c779-53dbdf3b648c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cpu\n"
          ]
        }
      ],
      "source": [
        "# Set device to GPU if available, else fallback to CPU\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")  # Print the selected device\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5MQBpgKtCuOF"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Improved CNN-based Generator for 28x28 images\n",
        "class CNNGenerator(nn.Module):\n",
        "    def __init__(self, latent_dim=128):\n",
        "        super(CNNGenerator, self).__init__()\n",
        "        self.latent_dim = latent_dim\n",
        "\n",
        "        # Fully Connected block: z → (128 x 7 x 7)\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(latent_dim, 256 * 7 * 7),  # More channels for richer feature maps\n",
        "            nn.BatchNorm1d(256 * 7 * 7),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Dropout(0.3)  # helps prevent mode collapse\n",
        "        )\n",
        "\n",
        "        # Deconvolution blocks\n",
        "        self.deconv = nn.Sequential(\n",
        "            # Upsample: 7x7 → 14x14\n",
        "            nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            # Upsample: 14x14 → 28x28\n",
        "            nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            # Final layer: produce 1 channel image\n",
        "            nn.Conv2d(64, 1, kernel_size=3, stride=1, padding=1),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "        # Apply custom weight initialization\n",
        "        self.apply(self._weights_init)\n",
        "\n",
        "    def _weights_init(self, m):\n",
        "        if isinstance(m, (nn.ConvTranspose2d, nn.Conv2d, nn.Linear)):\n",
        "            nn.init.xavier_uniform_(m.weight)  # DCGAN recommended init\n",
        "            if m.bias is not None:\n",
        "                nn.init.zeros_(m.bias)\n",
        "\n",
        "    def forward(self, z):\n",
        "        x = self.fc(z)                          # (batch_size, 256*7*7)\n",
        "        x = x.view(z.size(0), 256, 7, 7)        # reshape to (batch_size, 256, 7, 7)\n",
        "        img = self.deconv(x)                    # → (batch_size, 1, 28, 28)\n",
        "        return img\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PJEGi8dRCvto"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.utils as nn_utils\n",
        "\n",
        "class CNNDiscriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNNDiscriminator, self).__init__()\n",
        "\n",
        "        # === Feature Extractor ===\n",
        "        self.features = nn.Sequential(\n",
        "            # (1, 28, 28) → (64, 14, 14)\n",
        "            nn_utils.spectral_norm(nn.Conv2d(1, 64, kernel_size=4, stride=2, padding=1)),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Dropout(0.3),  # prevent overfitting\n",
        "\n",
        "            # (64, 14, 14) → (128, 7, 7)\n",
        "            nn_utils.spectral_norm(nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1)),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Dropout(0.3),\n",
        "\n",
        "            # Extra layer: (128, 7, 7) → (256, 7, 7) (no downsampling, richer features)\n",
        "            nn_utils.spectral_norm(nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1)),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Dropout(0.3)\n",
        "        )\n",
        "\n",
        "        # === Classifier ===\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(256 * 7 * 7, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "        # Apply DCGAN-style weight initialization\n",
        "        self.apply(self._weights_init)\n",
        "\n",
        "    def _weights_init(self, m):\n",
        "        if isinstance(m, (nn.Conv2d, nn.Linear)):\n",
        "            nn.init.xavier_uniform_(m.weight)\n",
        "            if m.bias is not None:\n",
        "                nn.init.zeros_(m.bias)\n",
        "\n",
        "    def forward(self, x):\n",
        "        features = self.features(x)      # Extract features\n",
        "        validity = self.classifier(features)  # Real/fake probability\n",
        "        return validity\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v7xNhIz7DLn4",
        "outputId": "804b9822-ba8e-42da-e445-4c5b6bd0af42"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting higher\n",
            "  Downloading higher-0.2.1-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from higher) (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->higher) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->higher) (4.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->higher) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->higher) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->higher) (2025.3.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->higher)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->higher)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->higher)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->higher)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->higher)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->higher)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->higher)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->higher)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->higher)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->higher) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->higher) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->higher) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->higher)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->higher) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->higher) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->higher) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->higher) (3.0.2)\n",
            "Downloading higher-0.2.1-py3-none-any.whl (27 kB)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m107.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m77.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m44.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m81.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, higher\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed higher-0.2.1 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ],
      "source": [
        "!pip install higher"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "da-0i_0dCywf",
        "outputId": "cd632f73-a9c9-446c-a041-ba922a5bfd37"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'higher'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2034468164.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mhigher\u001b[0m  \u001b[0;31m# for differentiable inner loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcopy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mMAML_GAN\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'higher'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import higher  # for differentiable inner loop\n",
        "from copy import deepcopy\n",
        "class MAML_GAN:\n",
        "    def __init__(self, latent_dim=128, inner_lr=0.012, meta_lr=0.0012):\n",
        "        self.latent_dim = latent_dim\n",
        "        self.inner_lr = inner_lr\n",
        "        self.meta_lr = meta_lr\n",
        "\n",
        "        self.generator = CNNGenerator(latent_dim).to(device)\n",
        "        self.discriminator = CNNDiscriminator().to(device)\n",
        "\n",
        "        # Meta-optimizers (outer loop)\n",
        "        self.meta_opt_G = optim.Adam(self.generator.parameters(), lr=self.meta_lr)\n",
        "        self.meta_opt_D = optim.Adam(self.discriminator.parameters(), lr=self.meta_lr)\n",
        "\n",
        "        self.loss_fn = nn.BCEWithLogitsLoss()\n",
        "\n",
        "\n",
        "    def inner_loop(self, gen, disc, loader, steps=2):\n",
        "        \"\"\" Differentiable inner loop using higher \"\"\"\n",
        "        opt_G = optim.SGD(gen.parameters(), lr=self.inner_lr)\n",
        "        opt_D = optim.SGD(disc.parameters(), lr=self.inner_lr)\n",
        "\n",
        "        # Create functional versions that allow gradient flow\n",
        "        with higher.innerloop_ctx(gen, opt_G, copy_initial_weights=False) as (fgen, diffopt_G), \\\n",
        "             higher.innerloop_ctx(disc, opt_D, copy_initial_weights=False) as (fdisc, diffopt_D):\n",
        "\n",
        "            for _ in range(steps):\n",
        "                real_imgs, _ = next(iter(loader))\n",
        "                real_imgs = real_imgs.to(device)\n",
        "                batch_size = real_imgs.size(0)\n",
        "\n",
        "                # ======== Discriminator update ========\n",
        "                z = torch.randn(batch_size, self.latent_dim).to(device)\n",
        "                fake_imgs = fgen(z).detach()\n",
        "\n",
        "                real_labels = torch.ones(batch_size, 1).to(device)\n",
        "                fake_labels = torch.zeros(batch_size, 1).to(device)\n",
        "\n",
        "                real_loss = self.loss_fn(fdisc(real_imgs), real_labels)\n",
        "                fake_loss = self.loss_fn(fdisc(fake_imgs), fake_labels)\n",
        "                d_loss = real_loss + fake_loss\n",
        "\n",
        "                diffopt_D.step(d_loss)\n",
        "\n",
        "                # ======== Generator update ========\n",
        "                z = torch.randn(batch_size, self.latent_dim).to(device)\n",
        "                fake_imgs = fgen(z)\n",
        "                g_loss = self.loss_fn(fdisc(fake_imgs), real_labels)\n",
        "\n",
        "                diffopt_G.step(g_loss)\n",
        "\n",
        "            # Return adapted functional models\n",
        "            return fgen, fdisc\n",
        "\n",
        "    def outer_loop(self, tasks, inner_steps=10, meta_steps=70):\n",
        "        \"\"\" Pure MAML outer loop \"\"\"\n",
        "        for step in range(meta_steps):\n",
        "            self.meta_opt_G.zero_grad()\n",
        "            self.meta_opt_D.zero_grad()\n",
        "\n",
        "            total_meta_loss_G = 0.0\n",
        "\n",
        "            for task_loader in tasks:\n",
        "                # Inner loop adaptation\n",
        "                fgen, fdisc = self.inner_loop(self.generator, self.discriminator, task_loader, steps=inner_steps)\n",
        "\n",
        "                # ======== Meta-loss computation ========\n",
        "                z = torch.randn(32, self.latent_dim).to(device)\n",
        "                fake_imgs = fgen(z)\n",
        "                pred = fdisc(fake_imgs)\n",
        "                meta_loss_G = self.loss_fn(pred, torch.ones_like(pred))\n",
        "\n",
        "                # Accumulate gradients\n",
        "                meta_loss_G.backward()\n",
        "                total_meta_loss_G += meta_loss_G.item()\n",
        "\n",
        "            # Outer loop update\n",
        "            self.meta_opt_G.step()\n",
        "            self.meta_opt_D.step()\n",
        "\n",
        "            if step % 5 == 0:\n",
        "                print(f\"[Meta Step {step}] Avg Meta Generator Loss: {total_meta_loss_G/len(tasks):.4f}\")\n",
        "\n",
        "    def adapt_to_digit_9(self, loader, steps=250):\n",
        "        print(\"Adapting to digit 9 with fine-tuning...\")\n",
        "        self.generator, self.discriminator = self._finetune(self.generator, self.discriminator, loader, steps)\n",
        "\n",
        "    def _finetune(self, gen, disc, loader, steps):\n",
        "        \"\"\" Non-differentiable fine-tuning (for evaluation) \"\"\"\n",
        "        opt_G = optim.SGD(gen.parameters(), lr=self.inner_lr)\n",
        "        opt_D = optim.SGD(disc.parameters(), lr=self.inner_lr)\n",
        "\n",
        "        for _ in range(steps):\n",
        "            real_imgs, _ = next(iter(loader))\n",
        "            real_imgs = real_imgs.to(device)\n",
        "            batch_size = real_imgs.size(0)\n",
        "\n",
        "            z = torch.randn(batch_size, self.latent_dim).to(device)\n",
        "            fake_imgs = gen(z).detach()\n",
        "\n",
        "            real_labels = torch.ones(batch_size, 1).to(device)\n",
        "            fake_labels = torch.zeros(batch_size, 1).to(device)\n",
        "\n",
        "            real_loss = self.loss_fn(disc(real_imgs), real_labels)\n",
        "            fake_loss = self.loss_fn(disc(fake_imgs), fake_labels)\n",
        "            d_loss = real_loss + fake_loss\n",
        "\n",
        "            opt_D.zero_grad()\n",
        "            d_loss.backward()\n",
        "            opt_D.step()\n",
        "\n",
        "            z = torch.randn(batch_size, self.latent_dim).to(device)\n",
        "            fake_imgs = gen(z)\n",
        "            g_loss = self.loss_fn(disc(fake_imgs), real_labels)\n",
        "\n",
        "            opt_G.zero_grad()\n",
        "            g_loss.backward()\n",
        "            opt_G.step()\n",
        "\n",
        "        return gen, disc\n",
        "\n",
        "    def generate(self, num_samples=25):\n",
        "        z = torch.randn(num_samples, self.latent_dim).to(device)\n",
        "        samples = self.generator(z)\n",
        "        return samples.detach().cpu()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "9TtMq_zBC0uF",
        "outputId": "1715d512-ca19-4ae3-e619-6e4e0bb6f6bc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 11.4MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 344kB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 2.72MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 5.89MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Meta Step 0] Avg Meta Generator Loss: 0.6322\n",
            "[Meta Step 5] Avg Meta Generator Loss: 0.3133\n",
            "[Meta Step 10] Avg Meta Generator Loss: 0.3133\n"
          ]
        }
      ],
      "source": [
        "from copy import deepcopy\n",
        "# -----------------------------\n",
        "# === Run MAML-GAN ===\n",
        "# -----------------------------\n",
        "if __name__ == '__main__':\n",
        "    transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.5], [0.5])\n",
        "    ])\n",
        "\n",
        "    dataset = MNIST(root='./data', train=True, transform=transform, download=True)\n",
        "\n",
        "    # Create tasks: each task has samples from one digit class (0 to 8)\n",
        "    tasks = []\n",
        "    for digit in range(9):  # Digits 0 to 8\n",
        "        indices = [i for i, (_, label) in enumerate(dataset) if label == digit]\n",
        "        subset = Subset(dataset, indices[:])  # Use 200 samples per task\n",
        "        loader = DataLoader(subset, batch_size=64, shuffle=True)\n",
        "        tasks.append(loader)\n",
        "\n",
        "    # Create separate loader for digit 9\n",
        "    indices_9 = [i for i, (_, label) in enumerate(dataset) if label == 9]\n",
        "    subset_9 = Subset(dataset, indices_9[:10])  # Few-shot digit 9\n",
        "    loader_9 = DataLoader(subset_9, batch_size=64, shuffle=True)\n",
        "\n",
        "    # Initialize model and train\n",
        "    gan = MAML_GAN()\n",
        "    gan.outer_loop(tasks, inner_steps=10, meta_steps=800)\n",
        "\n",
        "    # Adapt to digit 9\n",
        "    gan.adapt_to_digit_9(loader_9, steps=150)\n",
        "\n",
        "    # Generate samples\n",
        "    samples = gan.generate(10)\n",
        "\n",
        "    # Plot generated images\n",
        "    samples = [img.squeeze(0) for img in samples]\n",
        "    grid = torch.cat(samples, dim=1)\n",
        "    plt.figure(figsize=(15, 2))\n",
        "    plt.imshow(grid.numpy(), cmap='gray')\n",
        "    plt.title(\"Generated Digit 9 Samples After MAML Adaptation\")\n",
        "    plt.axis('off')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z6l8I2GA_IP8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "H_e4l2Pv_ITY",
        "outputId": "ad2b4ca4-aa79-44ad-b863-a42f36bb5aa7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m42.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m30.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m29.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m43.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.9/981.9 kB\u001b[0m \u001b[31m58.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 18.3MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 496kB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 4.62MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 7.24MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Starting True Second-Order MAML Training...\n",
            "\n",
            "[Epoch 1/25] D_meta_loss: 0.1822, G_meta_loss: 2.3212\n",
            "[Epoch 2/25] D_meta_loss: 0.1302, G_meta_loss: 2.7616\n",
            "[Epoch 3/25] D_meta_loss: 0.5824, G_meta_loss: 3.8898\n",
            "[Epoch 4/25] D_meta_loss: 0.0387, G_meta_loss: 3.9782\n",
            "[Epoch 5/25] D_meta_loss: 0.0673, G_meta_loss: 3.2394\n",
            "[Epoch 6/25] D_meta_loss: 0.2521, G_meta_loss: 2.6297\n",
            "[Epoch 7/25] D_meta_loss: 0.6223, G_meta_loss: 2.6480\n",
            "[Epoch 8/25] D_meta_loss: 2.4425, G_meta_loss: 0.2247\n",
            "[Epoch 9/25] D_meta_loss: 0.7423, G_meta_loss: 1.0292\n",
            "[Epoch 10/25] D_meta_loss: 1.4379, G_meta_loss: 0.4222\n",
            "[Epoch 11/25] D_meta_loss: 0.2941, G_meta_loss: 1.7147\n",
            "[Epoch 12/25] D_meta_loss: 0.7901, G_meta_loss: 0.7479\n",
            "[Epoch 13/25] D_meta_loss: 0.2003, G_meta_loss: 2.0174\n",
            "[Epoch 14/25] D_meta_loss: 1.9205, G_meta_loss: 0.1885\n",
            "[Epoch 15/25] D_meta_loss: 0.6239, G_meta_loss: 1.2481\n",
            "[Epoch 16/25] D_meta_loss: 0.8994, G_meta_loss: 0.9829\n",
            "[Epoch 17/25] D_meta_loss: 0.9439, G_meta_loss: 0.8498\n",
            "[Epoch 18/25] D_meta_loss: 0.9646, G_meta_loss: 0.7899\n",
            "[Epoch 19/25] D_meta_loss: 0.7443, G_meta_loss: 0.9351\n",
            "[Epoch 20/25] D_meta_loss: 0.9539, G_meta_loss: 0.6394\n",
            "[Epoch 21/25] D_meta_loss: 0.6995, G_meta_loss: 0.8595\n",
            "[Epoch 22/25] D_meta_loss: 0.4819, G_meta_loss: 1.1808\n",
            "[Epoch 23/25] D_meta_loss: 0.3886, G_meta_loss: 1.4241\n",
            "[Epoch 24/25] D_meta_loss: 0.9036, G_meta_loss: 0.6528\n",
            "[Epoch 25/25] D_meta_loss: 0.6192, G_meta_loss: 0.9284\n",
            "\n",
            "Meta-testing on digit 9...\n",
            "\n",
            "Adapt Step 1/3 | D_loss: 8.2280 | G_loss: 0.0030\n",
            "Adapt Step 2/3 | D_loss: 8.0109 | G_loss: 28.4781\n",
            "Adapt Step 3/3 | D_loss: 0.6629 | G_loss: 22.5199\n",
            "Adapt Step 4/3 | D_loss: 5.2839 | G_loss: 20.9723\n",
            "Adapt Step 5/3 | D_loss: 5.0713 | G_loss: 22.9679\n",
            "Adapt Step 6/3 | D_loss: 2.0680 | G_loss: 24.1078\n",
            "Adapt Step 7/3 | D_loss: 0.0075 | G_loss: 24.1965\n",
            "Adapt Step 8/3 | D_loss: 0.4386 | G_loss: 19.8144\n",
            "Adapt Step 9/3 | D_loss: 2.9477 | G_loss: 30.7045\n",
            "Adapt Step 10/3 | D_loss: 5.2121 | G_loss: 21.2294\n",
            "Adapt Step 11/3 | D_loss: 0.0005 | G_loss: 14.6219\n",
            "Adapt Step 12/3 | D_loss: 2.3176 | G_loss: 18.0358\n",
            "Adapt Step 13/3 | D_loss: 0.4081 | G_loss: 22.1250\n",
            "Adapt Step 14/3 | D_loss: 0.0338 | G_loss: 16.0422\n",
            "Adapt Step 15/3 | D_loss: 1.1792 | G_loss: 15.4396\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x300 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "FrechetInceptionDistance metric requires that `Torch-fidelity` is installed. Either install as `pip install torchmetrics[image]` or `pip install torch-fidelity`.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2267528201.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[0;31m# Evaluation Metrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[0;31m# -------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFrechetInceptionDistance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m \u001b[0mkid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKernelInceptionDistance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubset_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[0mis_metric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInceptionScore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchmetrics/image/fid.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, feature, reset_real_features, normalize, input_img_size, feature_extractor_weights_path, antialias, **kwargs)\u001b[0m\n\u001b[1;32m    333\u001b[0m             \u001b[0mnum_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_TORCH_FIDELITY_AVAILABLE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 335\u001b[0;31m                 raise ModuleNotFoundError(\n\u001b[0m\u001b[1;32m    336\u001b[0m                     \u001b[0;34m\"FrechetInceptionDistance metric requires that `Torch-fidelity` is installed.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m                     \u001b[0;34m\" Either install as `pip install torchmetrics[image]` or `pip install torch-fidelity`.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: FrechetInceptionDistance metric requires that `Torch-fidelity` is installed. Either install as `pip install torchmetrics[image]` or `pip install torch-fidelity`.",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "# ✅ Install dependencies\n",
        "!pip install torch torchvision matplotlib tqdm torchmetrics higher --quiet\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import MNIST\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "import torchvision.utils as vutils\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import random, os, higher\n",
        "from copy import deepcopy\n",
        "\n",
        "# Metrics\n",
        "from torchmetrics.image.fid import FrechetInceptionDistance\n",
        "from torchmetrics.image.inception import InceptionScore\n",
        "from torchmetrics.image.kid import KernelInceptionDistance\n",
        "\n",
        "# -------------------------------\n",
        "# Device setup\n",
        "# -------------------------------\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "# -------------------------------\n",
        "# Generator (DCGAN style CNN)\n",
        "# -------------------------------\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, z_dim=100, img_channels=1):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.ConvTranspose2d(z_dim, 128, 7, 1, 0, bias=False),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(128, 64, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(64, img_channels, 4, 2, 1, bias=False),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "    def forward(self, z):\n",
        "        return self.net(z)\n",
        "\n",
        "# -------------------------------\n",
        "# Discriminator (DCGAN style CNN)\n",
        "# -------------------------------\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, img_channels=1):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Conv2d(img_channels, 64, 4, 2, 1, bias=False),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(64, 128, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(128, 1, 7, 1, 0, bias=False),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.net(x).view(-1)\n",
        "\n",
        "# -------------------------------\n",
        "# Load MNIST\n",
        "# -------------------------------\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize(28),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "train_dataset = MNIST(root=\"./data\", train=True, download=True, transform=transform)\n",
        "test_dataset = MNIST(root=\"./data\", train=False, download=True, transform=transform)\n",
        "\n",
        "def get_digit_indices(dataset, digit, max_samples=None):\n",
        "    idx = [i for i, (_, y) in enumerate(dataset) if y == digit]\n",
        "    if max_samples:\n",
        "        idx = idx[:max_samples]\n",
        "    return idx\n",
        "\n",
        "# -------------------------------\n",
        "# Training Parameters\n",
        "# -------------------------------\n",
        "z_dim = 100\n",
        "inner_steps = 3\n",
        "inner_lr = 0.01\n",
        "outer_lr = 0.001\n",
        "meta_epochs = 25\n",
        "support_size_train = 64\n",
        "support_size_test = 32\n",
        "\n",
        "# Meta models\n",
        "metaG = Generator(z_dim).to(device)\n",
        "metaD = Discriminator().to(device)\n",
        "meta_optimizer = optim.Adam(\n",
        "    list(metaG.parameters()) + list(metaD.parameters()),\n",
        "    lr=outer_lr, betas=(0.5, 0.999)\n",
        ")\n",
        "loss_fn = nn.BCELoss()\n",
        "\n",
        "# -------------------------------\n",
        "# Meta-training on digits 0–8\n",
        "# -------------------------------\n",
        "print(\"\\nStarting True Second-Order MAML Training...\\n\")\n",
        "\n",
        "for epoch in range(meta_epochs):\n",
        "    g_meta_loss, d_meta_loss = 0, 0\n",
        "    meta_optimizer.zero_grad()\n",
        "\n",
        "    for digit in range(9):  # digits 0–8\n",
        "        support_idx = get_digit_indices(train_dataset, digit, support_size_train)\n",
        "        query_idx = get_digit_indices(test_dataset, digit, 64)\n",
        "\n",
        "        support_loader = DataLoader(Subset(train_dataset, support_idx), batch_size=support_size_train)\n",
        "        query_loader = DataLoader(Subset(test_dataset, query_idx), batch_size=len(query_idx))\n",
        "\n",
        "        x_support, _ = next(iter(support_loader))\n",
        "        x_query, _ = next(iter(query_loader))\n",
        "        x_support, x_query = x_support.to(device), x_query.to(device)\n",
        "\n",
        "        # Inner loop with higher\n",
        "        inner_optG = optim.SGD(metaG.parameters(), lr=inner_lr)\n",
        "        inner_optD = optim.SGD(metaD.parameters(), lr=inner_lr)\n",
        "\n",
        "        with higher.innerloop_ctx(metaG, inner_optG, copy_initial_weights=False) as (fG, diff_optG), \\\n",
        "             higher.innerloop_ctx(metaD, inner_optD, copy_initial_weights=False) as (fD, diff_optD):\n",
        "\n",
        "            for step in range(inner_steps):\n",
        "                z = torch.randn(support_size_train, z_dim, 1, 1).to(device)\n",
        "                fake = fG(z)\n",
        "                real = x_support\n",
        "\n",
        "                # Train D\n",
        "                real_labels = torch.ones(real.size(0), device=device)\n",
        "                fake_labels = torch.zeros(fake.size(0), device=device)\n",
        "                d_real = fD(real)\n",
        "                d_fake = fD(fake.detach())\n",
        "                d_loss = loss_fn(d_real, real_labels) + loss_fn(d_fake, fake_labels)\n",
        "                diff_optD.step(d_loss)\n",
        "\n",
        "                # Train G\n",
        "                z = torch.randn(support_size_train, z_dim, 1, 1).to(device)\n",
        "                fake = fG(z)\n",
        "                g_fake = fD(fake)\n",
        "                g_loss = loss_fn(g_fake, torch.ones_like(g_fake))\n",
        "                diff_optG.step(g_loss)\n",
        "\n",
        "            # Query loss after adaptation\n",
        "            z_q = torch.randn(len(x_query), z_dim, 1, 1).to(device)\n",
        "            fake_q = fG(z_q)\n",
        "            d_real_q = fD(x_query)\n",
        "            d_fake_q = fD(fake_q)\n",
        "            d_q_loss = loss_fn(d_real_q, torch.ones_like(d_real_q)) + \\\n",
        "                       loss_fn(d_fake_q, torch.zeros_like(d_fake_q))\n",
        "            g_q_loss = loss_fn(fD(fake_q), torch.ones_like(d_fake_q))\n",
        "\n",
        "            # Accumulate meta gradients (second-order!)\n",
        "            (d_q_loss + g_q_loss).backward()\n",
        "\n",
        "            d_meta_loss += d_q_loss.item()\n",
        "            g_meta_loss += g_q_loss.item()\n",
        "\n",
        "    meta_optimizer.step()\n",
        "    print(f\"[Epoch {epoch+1}/{meta_epochs}] D_meta_loss: {d_meta_loss/9:.4f}, G_meta_loss: {g_meta_loss/9:.4f}\")\n",
        "\n",
        "# -------------------------------\n",
        "# Meta-testing on digit 9\n",
        "# -------------------------------\n",
        "print(\"\\nMeta-testing on digit 9...\\n\")\n",
        "support_idx = get_digit_indices(train_dataset, 9, support_size_test)\n",
        "query_idx = get_digit_indices(test_dataset, 9, 64)\n",
        "\n",
        "support_loader = DataLoader(Subset(train_dataset, support_idx), batch_size=support_size_test)\n",
        "query_loader = DataLoader(Subset(test_dataset, query_idx), batch_size=len(query_idx))\n",
        "\n",
        "x_support, _ = next(iter(support_loader))\n",
        "x_query, _ = next(iter(query_loader))\n",
        "x_support, x_query = x_support.to(device), x_query.to(device)\n",
        "\n",
        "# Adapt meta-trained models to digit 9\n",
        "G = deepcopy(metaG)\n",
        "D = deepcopy(metaD)\n",
        "optG = optim.Adam(G.parameters(), lr=inner_lr, betas=(0.5, 0.999))\n",
        "optD = optim.Adam(D.parameters(), lr=inner_lr, betas=(0.5, 0.999))\n",
        "\n",
        "for step in range(15):\n",
        "    z = torch.randn(support_size_test, z_dim, 1, 1).to(device)\n",
        "    fake = G(z)\n",
        "    real = x_support\n",
        "    d_real = D(real)\n",
        "    d_fake = D(fake.detach())\n",
        "    d_loss = loss_fn(d_real, torch.ones_like(d_real)) + loss_fn(d_fake, torch.zeros_like(d_fake))\n",
        "\n",
        "    optD.zero_grad()\n",
        "    d_loss.backward()\n",
        "    optD.step()\n",
        "\n",
        "    fake = G(z)\n",
        "    g_loss = loss_fn(D(fake), torch.ones_like(D(fake)))\n",
        "    optG.zero_grad()\n",
        "    g_loss.backward()\n",
        "    optG.step()\n",
        "\n",
        "    print(f\"Adapt Step {step+1}/{inner_steps} | D_loss: {d_loss.item():.4f} | G_loss: {g_loss.item():.4f}\")\n",
        "\n",
        "# -------------------------------\n",
        "# Generate Digit 9 Samples\n",
        "# -------------------------------\n",
        "G.eval()\n",
        "z = torch.randn(10, z_dim, 1, 1).to(device)\n",
        "samples = G(z).cpu().detach()\n",
        "grid = vutils.make_grid(samples, nrow=10, normalize=True)\n",
        "plt.figure(figsize=(15,3))\n",
        "plt.imshow(np.transpose(grid, (1,2,0)))\n",
        "plt.axis(\"off\")\n",
        "plt.title(\"Generated Digit 9s after MAML Adaptation\")\n",
        "plt.show()\n",
        "\n",
        "# -------------------------------\n",
        "# Evaluation Metrics\n",
        "# -------------------------------\n",
        "fid = FrechetInceptionDistance(feature=64).to(device)\n",
        "kid = KernelInceptionDistance(subset_size=50).to(device)\n",
        "is_metric = InceptionScore().to(device)\n",
        "\n",
        "fid.update(samples.to(device), real=False)\n",
        "fid.update(x_query.to(device), real=True)\n",
        "print(\"FID:\", fid.compute().item())\n",
        "\n",
        "kid.update(samples.to(device), real=False)\n",
        "kid.update(x_query.to(device), real=True)\n",
        "print(\"KID:\", kid.compute()[0].item())\n",
        "\n",
        "is_metric.update(samples.to(device))\n",
        "print(\"Inception Score:\", is_metric.compute()[0].item())"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}